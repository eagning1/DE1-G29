{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/eagning1/DE1-G29/blob/main/DE1_G29.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Rzj3uCh8tcHJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "from collections import Counter, defaultdict\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download VADER lexicon if not already downloaded\n",
    "try:\n",
    "    nltk.data.find('vader_lexicon')\n",
    "except LookupError:\n",
    "    nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style for our plots\n",
    "plt.style.use('ggplot')\n",
    "sns.set(font_scale=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LyricsAnalyzer:\n",
    "    def __init__(self, matches: str, train: str):\n",
    "        \"\"\"\n",
    "        matches    : path to mxm_779k_matches.txt\n",
    "        train      : path to mxm_dataset_train.txt\n",
    "        \"\"\"\n",
    "        self.matches = matches\n",
    "        self.train = train\n",
    "        self.top_words = []\n",
    "        self.df_matches = None\n",
    "        self.df_lyrics = None\n",
    "        self.word_counts = None\n",
    "        self.sentiment_analyzer = SentimentIntensityAnalyzer() # Imported from NLTK/Vader\n",
    "        \n",
    "    def load_matches(self):\n",
    "        \"\"\"\n",
    "        Load and parse the matches file\n",
    "        \"\"\"\n",
    "        print(\"Loading matches data...\")\n",
    "        \n",
    "        # file columns (matches file)\n",
    "        columns = ['msd_track_id', 'msd_artist_name', 'msd_title', 'mxm_track_id', 'mxm_artist_name', 'mxm_title']\n",
    "        \n",
    "        data = []\n",
    "        with open(self.matches, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                if line.startswith('#'):\n",
    "                    continue\n",
    "                parts = line.strip().split('<SEP>')\n",
    "                if len(parts) == 6:\n",
    "                    data.append(parts)\n",
    "        \n",
    "        # create df\n",
    "        self.df_matches = pd.DataFrame(data, columns=columns)\n",
    "        print(f\"Loaded {len(self.df_matches)} matches\")\n",
    "\n",
    "        return self.df_matches\n",
    "    \n",
    "    def load_lyrics(self):\n",
    "        \"\"\"\n",
    "        Load and parse the lyrics training file\n",
    "        \"\"\"\n",
    "        print(\"Loading lyrics data...\")\n",
    "\n",
    "        # Get top words list\n",
    "        self.top_words = []\n",
    "        word_counts_data = []\n",
    "        \n",
    "        with open(self.train, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                if line.startswith('#'): # skip comments\n",
    "                    continue\n",
    "                elif line.startswith('%'):  # get top words\n",
    "                    self.top_words = line[1:].strip().split(',')\n",
    "                else:\n",
    "                    # get word counts\n",
    "                    parts = line.strip().split(',')\n",
    "                    if len(parts) >= 2:\n",
    "                        track_id = parts[0]\n",
    "                        mxm_track_id = parts[1]\n",
    "                        \n",
    "                        word_counts = {}\n",
    "                        for item in parts[2:]:\n",
    "                            if ':' in item:\n",
    "                                idx, count = item.split(':')\n",
    "                                word_idx = int(idx) - 1\n",
    "                                if word_idx < len(self.top_words):\n",
    "                                    word_counts[self.top_words[word_idx]] = int(count)\n",
    "                        \n",
    "                        word_counts_data.append({\n",
    "                            'track_id': track_id,\n",
    "                            'mxm_track_id': mxm_track_id,\n",
    "                            'word_counts': word_counts\n",
    "                        })\n",
    "        \n",
    "        # create df\n",
    "        self.df_lyrics = pd.DataFrame(word_counts_data)\n",
    "        print(f\"loaded lyrics, total of {len(self.df_lyrics)} songs with {len(self.top_words)} words.\")\n",
    "\n",
    "        return self.df_lyrics\n",
    "    \n",
    "    def merge_data(self):\n",
    "        \"\"\"\n",
    "        Merge the matches and lyrics data\n",
    "        \"\"\"\n",
    "        if self.df_matches is None:\n",
    "            self.load_matches()\n",
    "        if self.df_lyrics is None:\n",
    "            self.load_lyrics()\n",
    "        \n",
    "        # Merge on mxm_track_id\n",
    "        merged_df = pd.merge(\n",
    "            self.df_lyrics,\n",
    "            self.df_matches,\n",
    "            left_on='mxm_track_id',\n",
    "            right_on='mxm_track_id',\n",
    "            how='inner'\n",
    "        )\n",
    "        \n",
    "        print(f\"total data contains {len(merged_df)} songs\")\n",
    "\n",
    "        return merged_df\n",
    "    \n",
    "    def create_word_count_matrix(self):\n",
    "        \"\"\"\n",
    "        Convert sparse word counts to a matrix format\n",
    "        \"\"\"\n",
    "        if self.df_lyrics is None:\n",
    "            self.load_lyrics()\n",
    "        \n",
    "        word_count_matrix = np.zeros((len(self.df_lyrics), len(self.top_words)))\n",
    "        \n",
    "        for i, row in enumerate(self.df_lyrics['word_counts']):\n",
    "            for word, count in row.items():\n",
    "                if word in self.top_words:\n",
    "                    col_idx = self.top_words.index(word)\n",
    "                    word_count_matrix[i, col_idx] = count\n",
    "        \n",
    "        self.word_counts = pd.DataFrame(word_count_matrix, columns=self.top_words)\n",
    "\n",
    "        return self.word_counts\n",
    "    \n",
    "    def calculate_sentiment(self, merged_data=None):\n",
    "        \"\"\"\n",
    "        Calculate sentiment scores for each song based on its word counts\n",
    "        \"\"\"\n",
    "        if merged_data is None:\n",
    "            merged_data = self.merge_data()\n",
    "        \n",
    "        sentiment_scores = []\n",
    "        \n",
    "        for _, row in merged_data.iterrows():\n",
    "            word_counts = row['word_counts']\n",
    "            \n",
    "            pseudo_text = ' '.join([f\"{word} \" * count for word, count in word_counts.items()])\n",
    "            \n",
    "            # get sentiment scores\n",
    "            sentiment = self.sentiment_analyzer.polarity_scores(pseudo_text)\n",
    "            sentiment_scores.append({\n",
    "                'track_id': row['track_id'],\n",
    "                'artist': row['msd_artist_name'],\n",
    "                'title': row['msd_title'],\n",
    "                'negative': sentiment['neg'],\n",
    "                'neutral': sentiment['neu'],\n",
    "                'positive': sentiment['pos'],\n",
    "                'compound': sentiment['compound']\n",
    "            })\n",
    "        \n",
    "        sentiment_df = pd.DataFrame(sentiment_scores)\n",
    "\n",
    "        return sentiment_df\n",
    "    \n",
    "    def cluster_songs(self, n_clusters=5):\n",
    "        \"\"\"\n",
    "        Cluster songs using KMeans based on the used words.\n",
    "        Then add the cluster group to the original data.\n",
    "        \"\"\"\n",
    "        if self.word_counts is None:\n",
    "            self.create_word_count_matrix()\n",
    "        \n",
    "        # normalize word counts\n",
    "        scaler = StandardScaler()\n",
    "        scaled_features = scaler.fit_transform(self.word_counts)\n",
    "        \n",
    "        # clustering\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "        clusters = kmeans.fit_predict(scaled_features)\n",
    "        \n",
    "        clustered_data = self.df_lyrics.copy()\n",
    "        clustered_data['cluster'] = clusters\n",
    "        \n",
    "        return clustered_data, kmeans\n",
    "    \n",
    "    def reduce_dimensions(self, method='pca', n_components=2):\n",
    "        \"\"\"\n",
    "        Reduce dimensions of word count data for visualization.\n",
    "        Default recution method is Principal Component Analysis,\n",
    "            TSNE is also available.\n",
    "        The default number of components is 2.\n",
    "        \"\"\"\n",
    "        if self.word_counts is None:\n",
    "            self.create_word_count_matrix()\n",
    "        \n",
    "        # Normalize word counts\n",
    "        scaler = StandardScaler()\n",
    "        scaled_cols = scaler.fit_transform(self.word_counts)\n",
    "        \n",
    "        if method.lower() == 'pca':\n",
    "            reducer = PCA(n_components=n_components)\n",
    "        elif method.lower() == 'tsne':\n",
    "            reducer = TSNE(n_components=n_components, random_state=42)\n",
    "        else:\n",
    "            raise TypeError(\"The chosen method is not implemented.\\nPlease choose another.\")\n",
    "        \n",
    "        reduced_cols = reducer.fit_transform(scaled_cols)\n",
    "        \n",
    "        return reduced_cols\n",
    "    \n",
    "    def plot_most_common_words(self, top_n=20):\n",
    "        \"\"\"\n",
    "        Plot the most common words\n",
    "        \"\"\"\n",
    "        if self.word_counts is None:\n",
    "            self.create_word_count_matrix()\n",
    "        \n",
    "        # summarize word counts of all songs\n",
    "        total_counts = self.word_counts.sum().sort_values(ascending=False)\n",
    "        top_words = total_counts.head(top_n)\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.barplot(x=top_words.values, y=top_words.index)\n",
    "        plt.title(f'Top {top_n} Most Common Words')\n",
    "        plt.xlabel('Count')\n",
    "        plt.ylabel('Word')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        return plt\n",
    "    \n",
    "    def plot_sentiment_distribution(self, sentiment_df=None):\n",
    "        \"\"\"\n",
    "        Plot the distribution of sentiment scores\n",
    "        \"\"\"\n",
    "        if sentiment_df is None:\n",
    "            sentiment_df = self.calculate_sentiment()\n",
    "        \n",
    "        fig, axs = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        \n",
    "        # Plot distributions of each sentiment score\n",
    "        sns.histplot(sentiment_df['negative'], kde=True, ax=axs[0, 0], color='green')\n",
    "        axs[0, 0].set_title('Negative Sentiment Distribution')\n",
    "        \n",
    "        sns.histplot(sentiment_df['neutral'], kde=True, ax=axs[0, 1], color='blue')\n",
    "        axs[0, 1].set_title('Neutral Sentiment Distribution')\n",
    "        \n",
    "        sns.histplot(sentiment_df['positive'], kde=True, ax=axs[1, 0], color='grey')\n",
    "        axs[1, 0].set_title('Positive Sentiment Distribution')\n",
    "        \n",
    "        sns.histplot(sentiment_df['compound'], kde=True, ax=axs[1, 1], color='red')\n",
    "        axs[1, 1].set_title('Compound Sentiment Distribution')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "\n",
    "        return fig, axs\n",
    "    \n",
    "    def plot_cluster_visualization(self, clustered_data=None, kmeans=None, n_clusters=5):\n",
    "        \"\"\"\n",
    "        Visualize song clusters in reduced dimensional space\n",
    "        \"\"\"\n",
    "        if clustered_data is None or kmeans is None:\n",
    "            clustered_data, kmeans = self.cluster_songs(n_clusters)\n",
    "        \n",
    "        # For visualization, reduce dimensions to 2D\n",
    "        reduced_features = self.reduce_dimensions(method='pca', n_components=2)\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        scatter = plt.scatter(\n",
    "            reduced_features[:, 0], \n",
    "            reduced_features[:, 1], \n",
    "            c=clustered_data['cluster'], \n",
    "            cmap='viridis', \n",
    "            alpha=0.5\n",
    "        )\n",
    "        \n",
    "        # Plot cluster\n",
    "        centers = kmeans.cluster_centers_\n",
    "        if centers.shape[1] > 2:\n",
    "            pca = PCA(n_components=2)\n",
    "            pca.fit(reduced_features)\n",
    "            centers_2d = pca.transform(centers)\n",
    "        else:\n",
    "            centers_2d = centers\n",
    "            \n",
    "        plt.scatter(\n",
    "            centers_2d[:, 0], \n",
    "            centers_2d[:, 1], \n",
    "            c='red', \n",
    "            marker='X', \n",
    "            s=200, \n",
    "            alpha=0.8\n",
    "        )\n",
    "        \n",
    "        plt.colorbar(scatter, label='Cluster')\n",
    "        plt.title('Song clusters visualization')\n",
    "        plt.xlabel('component 1')\n",
    "        plt.ylabel('component 2')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        return plt\n",
    "    \n",
    "    def analyze_artist(self, artist_name):\n",
    "        \"\"\"\n",
    "        Analyze lyrics patterns for a specific artist\n",
    "        \"\"\"\n",
    "        merged_data = self.merge_data()\n",
    "        \n",
    "        # Filter for the artist\n",
    "        artist_data = merged_data[merged_data['msd_artist_name'].str.lower() == artist_name.lower()]\n",
    "        \n",
    "        if len(artist_data) == 0:\n",
    "            print(f\"No data found for artist: {artist_name}\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"Analyzing {len(artist_data)} songs by {artist_name}\")\n",
    "        \n",
    "        # Calculate sentiment for the artist's songs\n",
    "        artist_sentiment = self.calculate_sentiment(artist_data)\n",
    "        \n",
    "        # Get most common words for this artist\n",
    "        all_words = Counter()\n",
    "        for word_counts in artist_data['word_counts']:\n",
    "            all_words.update(word_counts)\n",
    "        \n",
    "        return {\n",
    "            'artist_data': artist_data,\n",
    "            'sentiment': artist_sentiment,\n",
    "            'common_words': all_words\n",
    "        }\n",
    "    \n",
    "    def compare_genres(self, genre_artist_mapping):\n",
    "        \"\"\"\n",
    "        Compare lyrics and sentiment patterns across different genres\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        genre_artist_mapping : dict\n",
    "            Dictionary mapping genre names to lists of artists in that genre\n",
    "        \"\"\"\n",
    "        merged_data = self.merge_data()\n",
    "        genre_stats = {}\n",
    "        \n",
    "        for genre, artists in genre_artist_mapping.items():\n",
    "            # Get data for all artists in this genre\n",
    "            genre_data = merged_data[merged_data['msd_artist_name'].str.lower().isin([a.lower() for a in artists])]\n",
    "            \n",
    "            if len(genre_data) == 0:\n",
    "                print(f\"No data found for genre: {genre}\")\n",
    "                continue\n",
    "                \n",
    "            print(f\"Analyzing {len(genre_data)} songs in the {genre} genre\")\n",
    "            \n",
    "            # Calculate sentiment \n",
    "            genre_sentiment = self.calculate_sentiment(genre_data)\n",
    "            \n",
    "            # Get most common words for this genre\n",
    "            genre_words = Counter()\n",
    "            for word_counts in genre_data['word_counts']:\n",
    "                genre_words.update(word_counts)\n",
    "            \n",
    "            genre_stats[genre] = {\n",
    "                'data': genre_data,\n",
    "                'sentiment': genre_sentiment,\n",
    "                'common_words': genre_words\n",
    "            }\n",
    "        \n",
    "        return genre_stats\n",
    "    \n",
    "    def plot_sentiment_by_genre(self, genre_stats):\n",
    "        \"\"\"Plot comparison of sentiment across genres\"\"\"\n",
    "        if not genre_stats:\n",
    "            return None\n",
    "        \n",
    "        # Prepare data for plotting\n",
    "        genre_names = list(genre_stats.keys())\n",
    "        sentiment_means = {\n",
    "            'negative': [genre_stats[g]['sentiment']['negative'].mean() for g in genre_names],\n",
    "            'neutral': [genre_stats[g]['sentiment']['neutral'].mean() for g in genre_names],\n",
    "            'positive': [genre_stats[g]['sentiment']['positive'].mean() for g in genre_names],\n",
    "            'compound': [genre_stats[g]['sentiment']['compound'].mean() for g in genre_names]\n",
    "        }\n",
    "        \n",
    "        # Create bar plot\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        x = np.arange(len(genre_names))\n",
    "        width = 0.2\n",
    "        \n",
    "        ax.bar(x - width*1.5, sentiment_means['negative'], width, label='Negative', color='red', alpha=0.7)\n",
    "        ax.bar(x - width*0.5, sentiment_means['neutral'], width, label='Neutral', color='gray', alpha=0.7)\n",
    "        ax.bar(x + width*0.5, sentiment_means['positive'], width, label='Positive', color='green', alpha=0.7)\n",
    "        ax.bar(x + width*1.5, sentiment_means['compound'], width, label='Compound', color='blue', alpha=0.7)\n",
    "        \n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(genre_names, rotation=45, ha='right')\n",
    "        ax.set_ylabel('Mean Sentiment Score')\n",
    "        ax.set_title('Sentiment Analysis by Genre')\n",
    "        ax.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return plt\n",
    "    \n",
    "    def run_full_analysis(self):\n",
    "        \"\"\"Run a complete analysis pipeline on the dataset\"\"\"\n",
    "        # Load and merge data\n",
    "        merged_data = self.merge_data()\n",
    "        \n",
    "        # Create word count matrix\n",
    "        self.create_word_count_matrix()\n",
    "        \n",
    "        # Calculate sentiment\n",
    "        sentiment_df = self.calculate_sentiment(merged_data)\n",
    "        \n",
    "        # Cluster songs\n",
    "        clustered_data, kmeans = self.cluster_songs(n_clusters=5)\n",
    "        \n",
    "        # Generate plots\n",
    "        plots = {\n",
    "            'common_words': self.plot_most_common_words(top_n=20),\n",
    "            'sentiment_distribution': self.plot_sentiment_distribution(sentiment_df)#,\n",
    "            #'clusters': self.plot_cluster_visualization(clustered_data, kmeans)\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            'merged_data': merged_data,\n",
    "            'sentiment': sentiment_df,\n",
    "            'clusters': clustered_data,\n",
    "            'plots': plots\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading matches data...\n",
      "Loaded 779056 matches\n",
      "Loading lyrics data...\n",
      "loaded lyrics, total of 210519 songs with 5000 words.\n",
      "total data contains 265353 songs\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 7.84 GiB for an array with shape (210519, 5000) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m analyzer \u001b[38;5;241m=\u001b[39m LyricsAnalyzer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmxm_779k_matches.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmxm_dataset_train.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Run the analysis\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43manalyzer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_full_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Show plots\u001b[39;00m\n\u001b[0;32m      8\u001b[0m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplots\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcommon_words\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshow()\n",
      "Cell \u001b[1;32mIn[16], line 396\u001b[0m, in \u001b[0;36mLyricsAnalyzer.run_full_analysis\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    393\u001b[0m merged_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerge_data()\n\u001b[0;32m    395\u001b[0m \u001b[38;5;66;03m# Create word count matrix\u001b[39;00m\n\u001b[1;32m--> 396\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_word_count_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;66;03m# Calculate sentiment\u001b[39;00m\n\u001b[0;32m    399\u001b[0m sentiment_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_sentiment(merged_data)\n",
      "Cell \u001b[1;32mIn[16], line 111\u001b[0m, in \u001b[0;36mLyricsAnalyzer.create_word_count_matrix\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf_lyrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_lyrics()\n\u001b[1;32m--> 111\u001b[0m word_count_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf_lyrics\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtop_words\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf_lyrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword_counts\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m word, count \u001b[38;5;129;01min\u001b[39;00m row\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 7.84 GiB for an array with shape (210519, 5000) and data type float64"
     ]
    }
   ],
   "source": [
    "# Initialize the analyzer with file paths\n",
    "analyzer = LyricsAnalyzer('mxm_779k_matches.txt', 'mxm_dataset_train.txt')\n",
    "\n",
    "# Run the analysis\n",
    "results = analyzer.run_full_analysis()\n",
    "\n",
    "# Show plots\n",
    "results['plots']['common_words'].show()\n",
    "results['plots']['sentiment_distribution'][0].show()\n",
    "#results['plots']['clusters'].show()\n",
    "\n",
    "# Example of comparing genres\n",
    "genre_mapping = {\n",
    "    'Rock': ['Queen', 'The Beatles', 'Led Zeppelin', 'Pink Floyd', 'Rolling Stones'],\n",
    "    'Pop': ['Michael Jackson', 'Madonna', 'Prince'],\n",
    "    'Rap': ['Eminem', 'Jay-Z', 'Tupac']\n",
    "}\n",
    "\n",
    "genre_stats = analyzer.compare_genres(genre_mapping)\n",
    "analyzer.plot_sentiment_by_genre(genre_stats).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mresults\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>mxm_track_id</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>msd_track_id</th>\n",
       "      <th>msd_artist_name</th>\n",
       "      <th>msd_title</th>\n",
       "      <th>mxm_artist_name</th>\n",
       "      <th>mxm_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAAAAV128F421A322</td>\n",
       "      <td>4623710</td>\n",
       "      <td>{'i': 6, 'the': 4, 'you': 2, 'to': 2, 'and': 5...</td>\n",
       "      <td>TRAAAAV128F421A322</td>\n",
       "      <td>Western Addiction</td>\n",
       "      <td>A Poor Recipe For Civic Cohesion</td>\n",
       "      <td>Western Addiction</td>\n",
       "      <td>A Poor Recipe for Civic Cohesion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAAABD128F429CF47</td>\n",
       "      <td>6477168</td>\n",
       "      <td>{'i': 10, 'you': 17, 'to': 8, 'and': 2, 'a': 2...</td>\n",
       "      <td>TRAAABD128F429CF47</td>\n",
       "      <td>The Box Tops</td>\n",
       "      <td>Soul Deep</td>\n",
       "      <td>The Box Tops</td>\n",
       "      <td>Soul Deep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAAAED128E0783FAB</td>\n",
       "      <td>2516445</td>\n",
       "      <td>{'i': 28, 'the': 15, 'you': 2, 'to': 12, 'and'...</td>\n",
       "      <td>TRAAAED128E0783FAB</td>\n",
       "      <td>Jamie Cullum</td>\n",
       "      <td>It's About Time</td>\n",
       "      <td>Jamie Cullum</td>\n",
       "      <td>It's About Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAAAEF128F4273421</td>\n",
       "      <td>3759847</td>\n",
       "      <td>{'i': 5, 'the': 4, 'you': 3, 'to': 2, 'and': 1...</td>\n",
       "      <td>TRAAAEF128F4273421</td>\n",
       "      <td>Adam Ant</td>\n",
       "      <td>Something Girls</td>\n",
       "      <td>Adam Ant</td>\n",
       "      <td>Something Girls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAAAEW128F42930C0</td>\n",
       "      <td>3783760</td>\n",
       "      <td>{'i': 4, 'to': 5, 'and': 7, 'a': 2, 'me': 4, '...</td>\n",
       "      <td>TRAAAEW128F42930C0</td>\n",
       "      <td>Broken Spindles</td>\n",
       "      <td>Burn My Body (Album Version)</td>\n",
       "      <td>Broken Spindles</td>\n",
       "      <td>Burn My Body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265348</th>\n",
       "      <td>TRZZZWS128F429CF87</td>\n",
       "      <td>3080645</td>\n",
       "      <td>{'a': 1, 'no': 9, 'que': 7, 'de': 1, 'y': 4, '...</td>\n",
       "      <td>TRZZZWS128F429CF87</td>\n",
       "      <td>Los Prisioneros</td>\n",
       "      <td>Que No Destrocen Tu Vida</td>\n",
       "      <td>Los Prisioneros</td>\n",
       "      <td>Que no destrocen tu vida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265349</th>\n",
       "      <td>TRZZZXA128F428ED56</td>\n",
       "      <td>2344272</td>\n",
       "      <td>{'i': 1, 'the': 13, 'you': 6, 'to': 5, 'and': ...</td>\n",
       "      <td>TRZZZXA128F428ED56</td>\n",
       "      <td>The God Awfuls</td>\n",
       "      <td>No Angels</td>\n",
       "      <td>The God Awfuls</td>\n",
       "      <td>No Angels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265350</th>\n",
       "      <td>TRZZZXV128F4289747</td>\n",
       "      <td>1417347</td>\n",
       "      <td>{'i': 13, 'the': 3, 'you': 17, 'to': 5, 'and':...</td>\n",
       "      <td>TRZZZXV128F4289747</td>\n",
       "      <td>BlackHawk</td>\n",
       "      <td>Stepping Stones</td>\n",
       "      <td>Blackhawk</td>\n",
       "      <td>Stepping Stones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265351</th>\n",
       "      <td>TRZZZYV128F92E996D</td>\n",
       "      <td>6849828</td>\n",
       "      <td>{'i': 10, 'the': 6, 'you': 20, 'and': 2, 'me':...</td>\n",
       "      <td>TRZZZYV128F92E996D</td>\n",
       "      <td>TLC</td>\n",
       "      <td>Dear Lie</td>\n",
       "      <td>TLC</td>\n",
       "      <td>Dear Lie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265352</th>\n",
       "      <td>TRZZZYX128F92D32C6</td>\n",
       "      <td>681124</td>\n",
       "      <td>{'i': 4, 'the': 18, 'to': 3, 'and': 6, 'a': 9,...</td>\n",
       "      <td>TRZZZYX128F92D32C6</td>\n",
       "      <td>Donald Fagen</td>\n",
       "      <td>Trans-Island Skyway (Album Version)</td>\n",
       "      <td>Donald Fagen</td>\n",
       "      <td>Trans-Island Skyway</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>265353 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  track_id mxm_track_id  \\\n",
       "0       TRAAAAV128F421A322      4623710   \n",
       "1       TRAAABD128F429CF47      6477168   \n",
       "2       TRAAAED128E0783FAB      2516445   \n",
       "3       TRAAAEF128F4273421      3759847   \n",
       "4       TRAAAEW128F42930C0      3783760   \n",
       "...                    ...          ...   \n",
       "265348  TRZZZWS128F429CF87      3080645   \n",
       "265349  TRZZZXA128F428ED56      2344272   \n",
       "265350  TRZZZXV128F4289747      1417347   \n",
       "265351  TRZZZYV128F92E996D      6849828   \n",
       "265352  TRZZZYX128F92D32C6       681124   \n",
       "\n",
       "                                              word_counts        msd_track_id  \\\n",
       "0       {'i': 6, 'the': 4, 'you': 2, 'to': 2, 'and': 5...  TRAAAAV128F421A322   \n",
       "1       {'i': 10, 'you': 17, 'to': 8, 'and': 2, 'a': 2...  TRAAABD128F429CF47   \n",
       "2       {'i': 28, 'the': 15, 'you': 2, 'to': 12, 'and'...  TRAAAED128E0783FAB   \n",
       "3       {'i': 5, 'the': 4, 'you': 3, 'to': 2, 'and': 1...  TRAAAEF128F4273421   \n",
       "4       {'i': 4, 'to': 5, 'and': 7, 'a': 2, 'me': 4, '...  TRAAAEW128F42930C0   \n",
       "...                                                   ...                 ...   \n",
       "265348  {'a': 1, 'no': 9, 'que': 7, 'de': 1, 'y': 4, '...  TRZZZWS128F429CF87   \n",
       "265349  {'i': 1, 'the': 13, 'you': 6, 'to': 5, 'and': ...  TRZZZXA128F428ED56   \n",
       "265350  {'i': 13, 'the': 3, 'you': 17, 'to': 5, 'and':...  TRZZZXV128F4289747   \n",
       "265351  {'i': 10, 'the': 6, 'you': 20, 'and': 2, 'me':...  TRZZZYV128F92E996D   \n",
       "265352  {'i': 4, 'the': 18, 'to': 3, 'and': 6, 'a': 9,...  TRZZZYX128F92D32C6   \n",
       "\n",
       "          msd_artist_name                            msd_title  \\\n",
       "0       Western Addiction     A Poor Recipe For Civic Cohesion   \n",
       "1            The Box Tops                            Soul Deep   \n",
       "2            Jamie Cullum                      It's About Time   \n",
       "3                Adam Ant                      Something Girls   \n",
       "4         Broken Spindles         Burn My Body (Album Version)   \n",
       "...                   ...                                  ...   \n",
       "265348    Los Prisioneros             Que No Destrocen Tu Vida   \n",
       "265349     The God Awfuls                            No Angels   \n",
       "265350          BlackHawk                      Stepping Stones   \n",
       "265351                TLC                             Dear Lie   \n",
       "265352       Donald Fagen  Trans-Island Skyway (Album Version)   \n",
       "\n",
       "          mxm_artist_name                         mxm_title  \n",
       "0       Western Addiction  A Poor Recipe for Civic Cohesion  \n",
       "1            The Box Tops                         Soul Deep  \n",
       "2            Jamie Cullum                   It's About Time  \n",
       "3                Adam Ant                   Something Girls  \n",
       "4         Broken Spindles                      Burn My Body  \n",
       "...                   ...                               ...  \n",
       "265348    Los Prisioneros          Que no destrocen tu vida  \n",
       "265349     The God Awfuls                         No Angels  \n",
       "265350          Blackhawk                   Stepping Stones  \n",
       "265351                TLC                          Dear Lie  \n",
       "265352       Donald Fagen               Trans-Island Skyway  \n",
       "\n",
       "[265353 rows x 8 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['merged_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAAAAV128F421A322</td>\n",
       "      <td>Western Addiction</td>\n",
       "      <td>A Poor Recipe For Civic Cohesion</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.7748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAAABD128F429CF47</td>\n",
       "      <td>The Box Tops</td>\n",
       "      <td>Soul Deep</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.9686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAAAED128E0783FAB</td>\n",
       "      <td>Jamie Cullum</td>\n",
       "      <td>It's About Time</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.9932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAAAEF128F4273421</td>\n",
       "      <td>Adam Ant</td>\n",
       "      <td>Something Girls</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.8689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAAAEW128F42930C0</td>\n",
       "      <td>Broken Spindles</td>\n",
       "      <td>Burn My Body (Album Version)</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.9100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265348</th>\n",
       "      <td>TRZZZWS128F429CF87</td>\n",
       "      <td>Los Prisioneros</td>\n",
       "      <td>Que No Destrocen Tu Vida</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.9607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265349</th>\n",
       "      <td>TRZZZXA128F428ED56</td>\n",
       "      <td>The God Awfuls</td>\n",
       "      <td>No Angels</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.9890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265350</th>\n",
       "      <td>TRZZZXV128F4289747</td>\n",
       "      <td>BlackHawk</td>\n",
       "      <td>Stepping Stones</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.2263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265351</th>\n",
       "      <td>TRZZZYV128F92E996D</td>\n",
       "      <td>TLC</td>\n",
       "      <td>Dear Lie</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.114</td>\n",
       "      <td>-0.9231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265352</th>\n",
       "      <td>TRZZZYX128F92D32C6</td>\n",
       "      <td>Donald Fagen</td>\n",
       "      <td>Trans-Island Skyway (Album Version)</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.9735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>265353 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  track_id             artist  \\\n",
       "0       TRAAAAV128F421A322  Western Addiction   \n",
       "1       TRAAABD128F429CF47       The Box Tops   \n",
       "2       TRAAAED128E0783FAB       Jamie Cullum   \n",
       "3       TRAAAEF128F4273421           Adam Ant   \n",
       "4       TRAAAEW128F42930C0    Broken Spindles   \n",
       "...                    ...                ...   \n",
       "265348  TRZZZWS128F429CF87    Los Prisioneros   \n",
       "265349  TRZZZXA128F428ED56     The God Awfuls   \n",
       "265350  TRZZZXV128F4289747          BlackHawk   \n",
       "265351  TRZZZYV128F92E996D                TLC   \n",
       "265352  TRZZZYX128F92D32C6       Donald Fagen   \n",
       "\n",
       "                                      title  negative  neutral  positive  \\\n",
       "0          A Poor Recipe For Civic Cohesion     0.081    0.769     0.151   \n",
       "1                                 Soul Deep     0.018    0.876     0.105   \n",
       "2                           It's About Time     0.029    0.831     0.140   \n",
       "3                           Something Girls     0.000    0.917     0.083   \n",
       "4              Burn My Body (Album Version)     0.134    0.835     0.031   \n",
       "...                                     ...       ...      ...       ...   \n",
       "265348             Que No Destrocen Tu Vida     0.287    0.713     0.000   \n",
       "265349                            No Angels     0.237    0.732     0.031   \n",
       "265350                      Stepping Stones     0.104    0.783     0.112   \n",
       "265351                             Dear Lie     0.147    0.739     0.114   \n",
       "265352  Trans-Island Skyway (Album Version)     0.028    0.853     0.119   \n",
       "\n",
       "        compound  \n",
       "0         0.7748  \n",
       "1         0.9686  \n",
       "2         0.9932  \n",
       "3         0.8689  \n",
       "4        -0.9100  \n",
       "...          ...  \n",
       "265348   -0.9607  \n",
       "265349   -0.9890  \n",
       "265350    0.2263  \n",
       "265351   -0.9231  \n",
       "265352    0.9735  \n",
       "\n",
       "[265353 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>mxm_track_id</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAAAAV128F421A322</td>\n",
       "      <td>4623710</td>\n",
       "      <td>{'i': 6, 'the': 4, 'you': 2, 'to': 2, 'and': 5...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAAABD128F429CF47</td>\n",
       "      <td>6477168</td>\n",
       "      <td>{'i': 10, 'you': 17, 'to': 8, 'and': 2, 'a': 2...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAAAED128E0783FAB</td>\n",
       "      <td>2516445</td>\n",
       "      <td>{'i': 28, 'the': 15, 'you': 2, 'to': 12, 'and'...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAAAEF128F4273421</td>\n",
       "      <td>3759847</td>\n",
       "      <td>{'i': 5, 'the': 4, 'you': 3, 'to': 2, 'and': 1...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAAAEW128F42930C0</td>\n",
       "      <td>3783760</td>\n",
       "      <td>{'i': 4, 'to': 5, 'and': 7, 'a': 2, 'me': 4, '...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210514</th>\n",
       "      <td>TRZZZWS128F429CF87</td>\n",
       "      <td>3080645</td>\n",
       "      <td>{'a': 1, 'no': 9, 'que': 7, 'de': 1, 'y': 4, '...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210515</th>\n",
       "      <td>TRZZZXA128F428ED56</td>\n",
       "      <td>2344272</td>\n",
       "      <td>{'i': 1, 'the': 13, 'you': 6, 'to': 5, 'and': ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210516</th>\n",
       "      <td>TRZZZXV128F4289747</td>\n",
       "      <td>1417347</td>\n",
       "      <td>{'i': 13, 'the': 3, 'you': 17, 'to': 5, 'and':...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210517</th>\n",
       "      <td>TRZZZYV128F92E996D</td>\n",
       "      <td>6849828</td>\n",
       "      <td>{'i': 10, 'the': 6, 'you': 20, 'and': 2, 'me':...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210518</th>\n",
       "      <td>TRZZZYX128F92D32C6</td>\n",
       "      <td>681124</td>\n",
       "      <td>{'i': 4, 'the': 18, 'to': 3, 'and': 6, 'a': 9,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210519 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  track_id mxm_track_id  \\\n",
       "0       TRAAAAV128F421A322      4623710   \n",
       "1       TRAAABD128F429CF47      6477168   \n",
       "2       TRAAAED128E0783FAB      2516445   \n",
       "3       TRAAAEF128F4273421      3759847   \n",
       "4       TRAAAEW128F42930C0      3783760   \n",
       "...                    ...          ...   \n",
       "210514  TRZZZWS128F429CF87      3080645   \n",
       "210515  TRZZZXA128F428ED56      2344272   \n",
       "210516  TRZZZXV128F4289747      1417347   \n",
       "210517  TRZZZYV128F92E996D      6849828   \n",
       "210518  TRZZZYX128F92D32C6       681124   \n",
       "\n",
       "                                              word_counts  cluster  \n",
       "0       {'i': 6, 'the': 4, 'you': 2, 'to': 2, 'and': 5...        2  \n",
       "1       {'i': 10, 'you': 17, 'to': 8, 'and': 2, 'a': 2...        2  \n",
       "2       {'i': 28, 'the': 15, 'you': 2, 'to': 12, 'and'...        2  \n",
       "3       {'i': 5, 'the': 4, 'you': 3, 'to': 2, 'and': 1...        2  \n",
       "4       {'i': 4, 'to': 5, 'and': 7, 'a': 2, 'me': 4, '...        2  \n",
       "...                                                   ...      ...  \n",
       "210514  {'a': 1, 'no': 9, 'que': 7, 'de': 1, 'y': 4, '...        2  \n",
       "210515  {'i': 1, 'the': 13, 'you': 6, 'to': 5, 'and': ...        2  \n",
       "210516  {'i': 13, 'the': 3, 'you': 17, 'to': 5, 'and':...        2  \n",
       "210517  {'i': 10, 'the': 6, 'you': 20, 'and': 2, 'me':...        2  \n",
       "210518  {'i': 4, 'the': 18, 'to': 3, 'and': 6, 'a': 9,...        2  \n",
       "\n",
       "[210519 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['clusters']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tNj96NopttSy"
   },
   "source": [
    "# Problem description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5g9ejSWtmd_"
   },
   "source": [
    "# Workbook Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y_rYZ3QktjOL"
   },
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BzLMnofktx5N"
   },
   "source": [
    "# Analysis"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOm6kK/hV474xvJnYQeU9ph",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
