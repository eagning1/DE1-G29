{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcbfbf6-f3e7-4d84-818b-e071c3d87d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, concat_ws, collect_list\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import time\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "def create_spark_session(workers):\n",
    "    \"\"\"\n",
    "    Creates and returns a Spark session with dynamic allocation and RDD settings.\n",
    "    \"\"\"\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"Lyrics Sentiment Analysis\") \\\n",
    "        .config(\"spark.executor.instances\", workers) \\\n",
    "        .getOrCreate()\n",
    "    spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "    return spark\n",
    "\n",
    "# Sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    score = analyzer.polarity_scores(text)[\"compound\"]\n",
    "    return \"positive\" if score > 0.05 else \"negative\" if score < -0.05 else \"neutral\"\n",
    "\n",
    "def run_experiment(workers, data_fraction, df):\n",
    "    \"\"\"\n",
    "    Runs the sentiment analysis experiment with the given number of workers and data fraction.\n",
    "    \"\"\"\n",
    "    spark = create_spark_session(workers)\n",
    "\n",
    "    # Ensure the DataFrame is clean before proceeding\n",
    "    df['track_id'] = df['track_id'].astype(str)\n",
    "    df['mxm_tid'] = df['mxm_tid'].astype(str)\n",
    "    df['word'] = df['word'].astype(str)\n",
    "    df['count'] = pd.to_numeric(df['count'], errors='coerce')  # Ensure 'count' is numeric\n",
    "    df = df.dropna(subset=['count'])  # Drop rows with NaN in 'count'\n",
    "\n",
    "    # If the DataFrame is still empty after cleaning, return early\n",
    "    if df.empty:\n",
    "        print(\"Error: After cleaning, the Pandas DataFrame is empty.\")\n",
    "        return\n",
    "\n",
    "    # Apply sampling (fraction) to the Pandas DataFrame before converting to Spark DataFrame\n",
    "    sampled_df = df.sample(frac=data_fraction, random_state=42)\n",
    "\n",
    "    # Define the schema for Spark DataFrame to ensure correct types\n",
    "    schema = StructType([\n",
    "        StructField(\"track_id\", StringType(), True),\n",
    "        StructField(\"mxm_tid\", StringType(), True),\n",
    "        StructField(\"word\", StringType(), True),\n",
    "        StructField(\"count\", IntegerType(), True)\n",
    "    ])\n",
    "\n",
    "    try:\n",
    "        # Convert the cleaned and sampled Pandas DataFrame to a Spark DataFrame with the defined schema\n",
    "        full_lyrics_df = spark.createDataFrame(sampled_df, schema=schema)\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting Pandas DataFrame to Spark DataFrame: {e}\")\n",
    "        return\n",
    "\n",
    "    print(\"Reconstructing lyrics...\")\n",
    "    lyrics_df = full_lyrics_df.groupBy(\"track_id\") \\\n",
    "        .agg(concat_ws(\" \", collect_list(\"word\")).alias(\"lyrics\"))\n",
    "    print(\"Lyrics reconstructed.\")\n",
    "\n",
    "    # Time the sentiment analysis\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Register sentiment UDF\n",
    "    sentiment_udf = spark.udf.register(\"sentiment\", analyze_sentiment)\n",
    "    sentiment_df = lyrics_df.withColumn(\"sentiment\", sentiment_udf(col(\"lyrics\")))\n",
    "\n",
    "    print(f\"Total rows: {sentiment_df.count()}\")\n",
    "\n",
    "    # Count sentiment distribution\n",
    "    sentiment_counts = sentiment_df.groupBy(\"sentiment\").count().take(10)\n",
    "    print(sentiment_counts)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Time: {elapsed_time:.2f}s\")\n",
    "\n",
    "    # Save the sentiment counts to a text file\n",
    "    with open(\"sentiment_output.txt\", \"w\") as output_file:\n",
    "        for row in sentiment_counts:\n",
    "            output_file.write(f\"{row['sentiment']}: {row['count']}\\n\")\n",
    "    print(\"Sentiment counts saved to sentiment_output.txt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d78e693-9f08-421e-8567-31c7f56ae6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_file(file_path):\n",
    "    \"\"\"\n",
    "    Loads data from a text file and returns a Pandas DataFrame.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            if line.startswith(\"#\") or not line.strip():  # Skip comments and empty lines\n",
    "                continue\n",
    "            parts = line.strip().split(\",\")  # Split by commas\n",
    "            if len(parts) < 3:  # Skip rows without word-count data\n",
    "                continue\n",
    "            track_id, mxm_tid = parts[:2]  # First two columns\n",
    "            words_counts = [wc.split(\":\") for wc in parts[2:] if \":\" in wc]  # Ensure word:count format\n",
    "\n",
    "            for wc in words_counts:\n",
    "                if len(wc) == 2:\n",
    "                    word, count = wc\n",
    "                    if count.isdigit():  # Ensure count is a valid integer\n",
    "                        data.append([track_id, mxm_tid, word, int(count)])\n",
    "\n",
    "    # Create Pandas DataFrame\n",
    "    df = pd.DataFrame(data, columns=[\"track_id\", \"mxm_tid\", \"word\", \"count\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc89f21-e5dd-4500-8031-322d092f2045",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data_from_file(\"mxm_dataset_train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e149af0-3402-4ee0-9897-661c5bfaef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = X\n",
    "data_fraction = X\n",
    "\n",
    "run_experiment(workers, data_fraction, df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
