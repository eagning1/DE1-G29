{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1cfd4f-4b22-4b27-8a6a-0b063e752841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# PostgreSQL connection details\n",
    "db_user = \"sparkuser\"\n",
    "db_password = \"9567\"\n",
    "db_host = \"localhost\"  # Change if needed\n",
    "db_port = \"5432\"  # Default PostgreSQL port\n",
    "db_name = \"lyricsdb\"\n",
    "\n",
    "# Create SQLAlchemy engine\n",
    "engine = create_engine(f\"postgresql+psycopg2://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323c495d-6d48-4e7a-b8eb-18566bb24eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_file_path = \"mxm_dataset_train.txt\"\n",
    "test_file_path = \"mxm_dataset_test.txt\"\n",
    "\n",
    "# Initialize lists to store the data\n",
    "words_data = []\n",
    "lyrics_data = []\n",
    "\n",
    "# Helper function to encode strings like the SQLite utility\n",
    "def encode_string(s):\n",
    "    return s.replace(\"'\", \"''\")\n",
    "\n",
    "# Parse the training data file for words\n",
    "with open(train_file_path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        if line.startswith('%'):\n",
    "            topwords = line.strip()[1:].split(',')\n",
    "            break\n",
    "\n",
    "# Add the words to the words table (DataFrame)\n",
    "words_df = pd.DataFrame(topwords, columns=[\"word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cec39cb-7a4b-4819-99bb-74777212e4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df.insert(0, 'id', range(1, len(words_df) + 1))\n",
    "words_df = words_df.rename(columns={'id':'word_id', 'word':'word'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58de8458-aecf-4b68-99d7-c250088059b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append data to an existing table\n",
    "words_df.to_sql(\"words\", engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4ba3f2-8e76-4b81-b1ed-280e79c580fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the training data file for lyrics\n",
    "train_file_path = \"mxm_dataset_train.txt\"\n",
    "lyrics_data = []\n",
    "with open(train_file_path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        if not line.strip() or line.startswith(('%', '#')):\n",
    "            continue\n",
    "\n",
    "        parts = line.strip().split(',')\n",
    "        track_id, mxm_tid = parts[:2]\n",
    "\n",
    "        # Split word and count pairs\n",
    "        for word_count in parts[2:]:\n",
    "            word, count = word_count.split(':')\n",
    "            lyrics_data.append([track_id, mxm_tid, word, int(count), 0])  # is_test = 0 for training data\n",
    "\n",
    "lyrics_df = pd.DataFrame(lyrics_data, columns=[\"track_id\", \"mxm_tid\", \"word\", \"count\", \"is_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4f5db0-aa77-410e-9c04-ac961fd3b4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_df = lyrics_df.rename(columns={'word':'word_id'})\n",
    "lyrics_df['is_test'] = lyrics_df['is_test'].astype(bool)\n",
    "lyrics_df.insert(5, 'l_id', range(1, len(lyrics_df) + 1))\n",
    "lyrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6540a080-7191-4bbe-8ebd-c521b91800a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(lyrics_df), 50000):\n",
    "    if (i+50000) < len(lyrics_df):\n",
    "        lyrics_df[i+1:i+50000].to_sql(\"lyrics\", engine, if_exists=\"append\", index=False)\n",
    "    else:\n",
    "        lyrics_df[i+1:].to_sql(\"lyrics\", engine, if_exists=\"append\", index=False)\n",
    "\n",
    "    print(f\"Rows from {i+1} to {i+50000} uploaded\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
